{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68fce336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca4291c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/admin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/admin/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a15a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data: str):\n",
    "    cleaning_txt01 = data.replace('\\n', '').lower()\n",
    "    cleaning_txt02 = re.sub(r'[^a-z0-9 ]', '', cleaning_txt01)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(cleaning_txt02)\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    final_cleaned_data = \" \".join(filtered_tokens)\n",
    "    return final_cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0382960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resume4.pdf', 'resume5.pdf', 'resume2.pdf', 'resume3.pdf', 'resume1.pdf']\n"
     ]
    }
   ],
   "source": [
    "root_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "raw_data_path = root_path+'/data/raw'\n",
    "clean_data_path = root_path+'/data/cleaned'\n",
    "\n",
    "raw_resuem_files = os.listdir(raw_data_path)\n",
    "resume_files = []\n",
    "\n",
    "for file in raw_resuem_files:\n",
    "    if re.search(r'\\.pdf$', file):\n",
    "        resume_files.append(file)\n",
    "\n",
    "print(resume_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f62fd9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_names</th>\n",
       "      <th>raw_texts</th>\n",
       "      <th>clean_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resume4.pdf</td>\n",
       "      <td>OLIVIA WILSON\\nMARKETING MANAGER\\nWORK EXPERIE...</td>\n",
       "      <td>olivia wilsonmarketing managerwork experiencec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resume5.pdf</td>\n",
       "      <td>Supervise and ensure timely delivery and deliv...</td>\n",
       "      <td>supervise ensure timely delivery delivery offo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resume2.pdf</td>\n",
       "      <td>F A R A H   M A R T I N\\nDATA ANALYST\\nCONTACT...</td>\n",
       "      <td>f r h r ndata analystcontactfarahmartinemailco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resume3.pdf</td>\n",
       "      <td>Accomplished full-stack\\ndeveloper with track ...</td>\n",
       "      <td>accomplished fullstackdeveloper track recordof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resume1.pdf</td>\n",
       "      <td>KAUNG SI THU Junior Data Scientist | Data Anal...</td>\n",
       "      <td>kaung si thu junior data scientist data analys...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_names                                          raw_texts  \\\n",
       "0  resume4.pdf  OLIVIA WILSON\\nMARKETING MANAGER\\nWORK EXPERIE...   \n",
       "1  resume5.pdf  Supervise and ensure timely delivery and deliv...   \n",
       "2  resume2.pdf  F A R A H   M A R T I N\\nDATA ANALYST\\nCONTACT...   \n",
       "3  resume3.pdf  Accomplished full-stack\\ndeveloper with track ...   \n",
       "4  resume1.pdf  KAUNG SI THU Junior Data Scientist | Data Anal...   \n",
       "\n",
       "                                         clean_texts  \n",
       "0  olivia wilsonmarketing managerwork experiencec...  \n",
       "1  supervise ensure timely delivery delivery offo...  \n",
       "2  f r h r ndata analystcontactfarahmartinemailco...  \n",
       "3  accomplished fullstackdeveloper track recordof...  \n",
       "4  kaung si thu junior data scientist data analys...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = {\n",
    "    'file_names': [],\n",
    "    'raw_texts': [],\n",
    "    'clean_texts':[]\n",
    "}\n",
    "\n",
    "try:\n",
    "    raw_texts = []\n",
    "    for file in resume_files:\n",
    "        reader = PdfReader(raw_data_path+\"/\"+file)\n",
    "        full_text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text = page.extract_text()\n",
    "            full_text += text\n",
    "        raw_texts.append(full_text)\n",
    "        final_cleaned_data = clean_data(full_text)\n",
    "        data_dict['file_names'].append(file)\n",
    "        data_dict['raw_texts'].append(full_text)\n",
    "        data_dict['clean_texts'].append(final_cleaned_data)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Failed to read one or more pdf files.\", e)\n",
    "\n",
    "df = pd.DataFrame.from_dict(data_dict)\n",
    "df.to_csv(clean_data_path+'/resume_cleaned.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ed3ad31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample data scientist job description company x rely insightful data power systems solutions seeking experienced data scientist deliver insights daily basis ideal candidate mathematical statistical expertise along natural curiosity creative mind mining interpreting cleaning data person relied ask questions connect dots uncover hidden opportunities realizing datas full potential part team specialists data scientist slice dice data using various methods create new visions future objectives role collaborate product design engineering teams develop understanding needs research devise innovative statistical models data analysis communicate findings stakeholders enable smarter business processes using analytics meaningful insights keep current technical industry developments responsibilities serve lead data strategist identify integrate new datasets leveraged product capabilities work closely engineering team development data products execute analytical experiments help solve problems across various domains industries identify relevant data sources sets mine client business needs collect large structured unstructured datasets variables devise utilize algorithms models mine bigdata stores perform data error analysis improve models clean validate data uniformity accuracy analyze data trends patterns interpret data clear objectives mind implement analytical models production collaborating software developers machinelearning engineers required skills qualifications seven years experience data science proficiency data mining mathematics statistical analysis advanced experience pattern recognition predictive modeling experience excel powerpoint tableau sql programming languages ex javapython sas ability work effectively dynamic researchoriented group several concurrent projects preferred skills qualifications bachelors degree equivalent statistics applied mathematics related discipline two years project management experience professional certification\n"
     ]
    }
   ],
   "source": [
    "with open(raw_data_path+'/job_description.txt', 'r') as f:\n",
    "    jd = f.readlines()\n",
    "\n",
    "jd = \" \".join(jd)\n",
    "jd_cleaned = clean_data(jd)\n",
    "\n",
    "with open(clean_data_path+'/job_description_cleaned.txt', 'w') as f:\n",
    "    f.write(jd_cleaned)\n",
    "\n",
    "print(jd_cleaned)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "The Resume Roaster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
